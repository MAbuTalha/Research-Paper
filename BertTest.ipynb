{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertTest.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6EM/Ly8/1SLe1En3zdzMw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MAbuTalha/Research-Paper/blob/main/BertTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHLBs-9VF6hq"
      },
      "source": [
        "# verify GPU availability\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  raise SystemError('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUkvYq2sGv16"
      },
      "source": [
        "import torch\r\n",
        "\r\n",
        "print(torch.cuda.current_device())\r\n",
        "\r\n",
        "\r\n",
        "print(torch.cuda.device(0))\r\n",
        "print(torch.cuda.device_count())\r\n",
        "print(torch.cuda.get_device_name(0))\r\n",
        "print(torch.cuda.is_available())\r\n",
        "\r\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4VPI2HaG9Ch"
      },
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcuq_Wf5HA26"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "# Set notebook mode to work in offline\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "import re\r\n",
        "import re\r\n",
        "import string\r\n",
        "import sklearn\r\n",
        "import itertools\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_HY3NinHFyJ"
      },
      "source": [
        "!pip install simpletransformers\r\n",
        "from simpletransformers.classification import ClassificationModel\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVMq3rHEHfMp"
      },
      "source": [
        "from simpletransformers.classification import ClassificationModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t3kU5ErHl-6"
      },
      "source": [
        "from google.colab import files\r\n",
        "TestData = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCxVoY9-JdHv"
      },
      "source": [
        "for fn in TestData.keys():\r\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\r\n",
        "      name=fn, length=len(TestData[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4w-QI31J4U5"
      },
      "source": [
        "train_df =pd.read_csv('train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MEyUnBgKXTP"
      },
      "source": [
        "train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6T9-5MJKu9v"
      },
      "source": [
        "test_df =pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECgvQ-34Kz6A"
      },
      "source": [
        "test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZYk7PugK56v"
      },
      "source": [
        "contractions = { \r\n",
        "\"ain't\": \"am not\",\r\n",
        "\"aren't\": \"are not\",\r\n",
        "\"can't\": \"cannot\",\r\n",
        "\"can't've\": \"cannot have\",\r\n",
        "\"'cause\": \"because\",\r\n",
        "\"could've\": \"could have\",\r\n",
        "\"couldn't\": \"could not\",\r\n",
        "\"couldn't've\": \"could not have\",\r\n",
        "\"didn't\": \"did not\",\r\n",
        "\"doesn't\": \"does not\",\r\n",
        "\"don't\": \"do not\",\r\n",
        "\"hadn't\": \"had not\",\r\n",
        "\"hadn't've\": \"had not have\",\r\n",
        "\"hasn't\": \"has not\",\r\n",
        "\"haven't\": \"have not\",\r\n",
        "\"he'd\": \"he would\",\r\n",
        "\"he'd've\": \"he would have\",\r\n",
        "\"he'll\": \"he will\",\r\n",
        "\"he's\": \"he is\",\r\n",
        "\"how'd\": \"how did\",\r\n",
        "\"how'll\": \"how will\",\r\n",
        "\"how's\": \"how is\",\r\n",
        "\"i'd\": \"i would\",\r\n",
        "\"i'll\": \"i will\",\r\n",
        "\"i'm\": \"i am\",\r\n",
        "\"i've\": \"i have\",\r\n",
        "\"isn't\": \"is not\",\r\n",
        "\"it'd\": \"it would\",\r\n",
        "\"it'll\": \"it will\",\r\n",
        "\"it's\": \"it is\",\r\n",
        "\"let's\": \"let us\",\r\n",
        "\"ma'am\": \"madam\",\r\n",
        "\"mayn't\": \"may not\",\r\n",
        "\"might've\": \"might have\",\r\n",
        "\"mightn't\": \"might not\",\r\n",
        "\"must've\": \"must have\",\r\n",
        "\"mustn't\": \"must not\",\r\n",
        "\"needn't\": \"need not\",\r\n",
        "\"oughtn't\": \"ought not\",\r\n",
        "\"shan't\": \"shall not\",\r\n",
        "\"sha'n't\": \"shall not\",\r\n",
        "\"she'd\": \"she would\",\r\n",
        "\"she'll\": \"she will\",\r\n",
        "\"she's\": \"she is\",\r\n",
        "\"should've\": \"should have\",\r\n",
        "\"shouldn't\": \"should not\",\r\n",
        "\"that'd\": \"that would\",\r\n",
        "\"that's\": \"that is\",\r\n",
        "\"there'd\": \"there had\",\r\n",
        "\"there's\": \"there is\",\r\n",
        "\"they'd\": \"they would\",\r\n",
        "\"they'll\": \"they will\",\r\n",
        "\"they're\": \"they are\",\r\n",
        "\"they've\": \"they have\",\r\n",
        "\"wasn't\": \"was not\",\r\n",
        "\"we'd\": \"we would\",\r\n",
        "\"we'll\": \"we will\",\r\n",
        "\"we're\": \"we are\",\r\n",
        "\"we've\": \"we have\",\r\n",
        "\"weren't\": \"were not\",\r\n",
        "\"what'll\": \"what will\",\r\n",
        "\"what're\": \"what are\",\r\n",
        "\"what's\": \"what is\",\r\n",
        "\"what've\": \"what have\",\r\n",
        "\"where'd\": \"where did\",\r\n",
        "\"where's\": \"where is\",\r\n",
        "\"who'll\": \"who will\",\r\n",
        "\"who's\": \"who is\",\r\n",
        "\"won't\": \"will not\",\r\n",
        "\"wouldn't\": \"would not\",\r\n",
        "\"you'd\": \"you would\",\r\n",
        "\"you'll\": \"you will\",\r\n",
        "\"you're\": \"you are\",\r\n",
        "\"thx\"   : \"thanks\"\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dyLkhLFK7fo"
      },
      "source": [
        "def remove_contractions(text):\r\n",
        "    return contractions[text.lower()] if text.lower() in contractions.keys() else text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U3XLKkoK7oP"
      },
      "source": [
        "train_df.text=train_df.text.apply(remove_contractions)\r\n",
        "test_df.text=test_df.text.apply(remove_contractions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTydTUT5K7wu"
      },
      "source": [
        "def clean_dataset(text):\r\n",
        "    # Remove hashtag while keeping hashtag text\r\n",
        "    text = re.sub(r'#','', text)\r\n",
        "    # Remove HTML special entities (e.g. &amp;)\r\n",
        "    text = re.sub(r'\\&\\w*;', '', text)\r\n",
        "    # Remove tickers\r\n",
        "    text = re.sub(r'\\$\\w*', '', text)\r\n",
        "    # Remove hyperlinks\r\n",
        "    text = re.sub(r'https?:\\/\\/.*\\/\\w*', '', text)\r\n",
        "    # Remove whitespace (including new line characters)\r\n",
        "    text = re.sub(r'\\s\\s+','', text)\r\n",
        "    text = re.sub(r'[ ]{2, }',' ',text)\r\n",
        "    # Remove URL, RT, mention(@)\r\n",
        "    text=  re.sub(r'http(\\S)+', '',text)\r\n",
        "    text=  re.sub(r'http ...', '',text)\r\n",
        "    text=  re.sub(r'(RT|rt)[ ]*@[ ]*[\\S]+','',text)\r\n",
        "    text=  re.sub(r'RT[ ]?@','',text)\r\n",
        "    text = re.sub(r'@[\\S]+','',text)\r\n",
        "    # Remove words with 4 or fewer letters\r\n",
        "    text = re.sub(r'\\b\\w{1,4}\\b', '', text)\r\n",
        "    #&, < and >\r\n",
        "    text = re.sub(r'&amp;?', 'and',text)\r\n",
        "    text = re.sub(r'&lt;','<',text)\r\n",
        "    text = re.sub(r'&gt;','>',text)\r\n",
        "    # Remove characters beyond Basic Multilingual Plane (BMP) of Unicode:\r\n",
        "    text= ''.join(c for c in text if c <= '\\uFFFF') \r\n",
        "    text = text.strip()\r\n",
        "    # Remove misspelling words\r\n",
        "    text = ''.join(''.join(s)[:2] for _, s in itertools.groupby(text))\r\n",
        "    # Remove emoji\r\n",
        "    text = emoji.demojize(text)\r\n",
        "    text = text.replace(\":\",\" \")\r\n",
        "    text = ' '.join(text.split()) \r\n",
        "    text = re.sub(\"([^\\x00-\\x7F])+\",\" \",text)\r\n",
        "    # Remove Mojibake (also extra spaces)\r\n",
        "    text = ' '.join(re.sub(\"[^\\u4e00-\\u9fa5\\u0030-\\u0039\\u0041-\\u005a\\u0061-\\u007a]\", \" \", text).split())\r\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGm3C4iNK7ze"
      },
      "source": [
        "#!pip install emoji\r\n",
        "import emoji \r\n",
        "train_df.text=train_df.text.apply(clean_dataset)\r\n",
        "test_df.text=test_df.text.apply(clean_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7UyDpHSK77m"
      },
      "source": [
        "X_train_clean= train_df.text\r\n",
        "X_test_clean = test_df.text\r\n",
        "y_train_clean= train_df.label\r\n",
        "y_test_clean = test_df.label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sAi3l9mLjZx"
      },
      "source": [
        "train_df_clean = pd.concat([X_train_clean, y_train_clean], axis=1)\r\n",
        "print(\"Shape of training data set: \", train_df_clean.shape)\r\n",
        "print(\"View of data set: \", train_df_clean.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lishsw21LjcW"
      },
      "source": [
        "eval_df_clean = pd.concat([X_test_clean, y_test_clean], axis=1)\r\n",
        "print(\"Shape of Eval data set: \", eval_df_clean.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tULbWLxQLjfO"
      },
      "source": [
        "bert_train_args = {\r\n",
        "    'learning_rate':5e-5,\r\n",
        "    'evaluate_during_training': True,\r\n",
        "    'logging_steps': 100,\r\n",
        "    'num_train_epochs': 1,\r\n",
        "    'evaluate_during_training_steps': 100,\r\n",
        "    'save_eval_checkpoints': False,\r\n",
        "    'train_batch_size': 32,\r\n",
        "    'eval_batch_size': 64,\r\n",
        "    'overwrite_output_dir': True,\r\n",
        "    'output_dir':'D:/Output-Bert-Test',\r\n",
        "    'fp16': False,\r\n",
        "    'n_gpu':1,\r\n",
        "    'wandb_project': \"Bert-Model-Test\"\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at4JL9gDLjht"
      },
      "source": [
        "model_BertTest = ClassificationModel('bert', 'bert-base-cased', num_labels=2, use_cuda=True, cuda_device=0, args=bert_train_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf7P-jCYLjkw"
      },
      "source": [
        "model_BertTest.train_model(train_df_clean, eval_df=eval_df_clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT8aPkPvWynt"
      },
      "source": [
        "result, model_outputs, wrong_predictions = model_BertTest.eval_model(eval_df_clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_n9xM1RYzKb"
      },
      "source": [
        "from sklearn.metrics import f1_score,accuracy_score,classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5QZWX_LXmFk"
      },
      "source": [
        "predictions = []\r\n",
        "for x in model_outputs:\r\n",
        "    predictions.append(np.argmax(x))\r\n",
        "\r\n",
        "print('f1 score:', f1_score(eval_df_clean['label'], predictions))\r\n",
        "print('Accuracy score:', accuracy_score(eval_df_clean['label'], predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGJUDKrEZp66"
      },
      "source": [
        "# **RoBerta**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stgPFMZHZo6k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}